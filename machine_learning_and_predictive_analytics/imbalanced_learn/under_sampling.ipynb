{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Under-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[under-sampling page](https://imbalanced-learn.org/stable/under_sampling.html)\n",
    "\n",
    "One way of handling imbalanced datasets is to reduce the number of observations from all classes but the minority class. \n",
    "The minority class is that with the least number of observations. \n",
    "The most well known algorithm in this group is random undersampling, where samples from the targeted classes are removed at random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These algorithms can be grouped based on their undersampling strategy into:\n",
    "\n",
    "* Prototype generation methods.\n",
    "\n",
    "* Prototype selection methods.\n",
    "\n",
    "And within the latter, we find:\n",
    "\n",
    "* Controlled undersampling\n",
    "\n",
    "* Cleaning methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Prototype generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an original data set S, prototype generation algorithms will generate a new set S'\n",
    " where |S'| < |S| and S' not a subset of S.  \n",
    "In other words, prototype generation techniques will reduce the number of samples in the targeted classes but the remaining samples are generated — and not selected — from the original set.\n",
    "\n",
    "`ClusterCentroids` makes use of K-means to reduce the number of samples. Therefore, each class will be synthesized with the centroids of the K-means method instead of the original samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(np.int64(0), 64), (np.int64(1), 262), (np.int64(2), 4674)]\n",
      "[(np.int64(0), 64), (np.int64(1), 64), (np.int64(2), 64)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=5000, n_features=2, n_informative=2,\n",
    "                           n_redundant=0, n_repeated=0, n_classes=3,\n",
    "                           n_clusters_per_class=1,\n",
    "                           weights=[0.01, 0.05, 0.94],\n",
    "                           class_sep=0.8, random_state=0)\n",
    "print(sorted(Counter(y).items()))\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "cc = ClusterCentroids(random_state=0)\n",
    "X_resampled, y_resampled = cc.fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://imbalanced-learn.org/stable/_images/sphx_glr_plot_comparison_under_sampling_001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ClusterCentroids` offers an efficient way to represent the data cluster with a reduced number of samples. \n",
    "Keep in mind that this method requires that your data are grouped into clusters. \n",
    "In addition, the number of centroids should be set such that the under-sampled clusters are representative of the original one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Prototype selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decision_trees_practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
