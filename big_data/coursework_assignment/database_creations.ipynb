{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data and Database Creations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to gather data from a kaggle dataset into a sqlite db and api calls to place json into a local mongoDB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Dataset from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'data' already exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"data\"\n",
    "\n",
    "# creating folder for data to be held, .gitignore data/ added also\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "    print(f\"Folder '{folder_path}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Folder '{folder_path}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the Kaggle username and key as environment variables for the session\n",
    "# used .env instead json file from kaggle\n",
    "os.environ[\"KAGGLE_USERNAME\"] = os.getenv(\"KAGGLE_USERNAME\")\n",
    "os.environ[\"KAGGLE_KEY\"] = os.getenv(\"KAGGLE_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# Function to download Kaggle dataset\n",
    "def download_kaggle_dataset(owner, dataset_name, download_path=\"data\"):\n",
    "    os.makedirs(download_path, exist_ok=True)\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_download_files(f\"{owner}/{dataset_name}\", path=download_path, unzip=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/yakhyojon/tiktok\n"
     ]
    }
   ],
   "source": [
    "# downloading kaggle tiktok dataset\n",
    "download_kaggle_dataset(\"yakhyojon\", \"tiktok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Dataset into a sqlite DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chatgpt assited in creating db. More tables should be made to be normalized but normalization is not the focus of coursework. I wish to practice interacting with a db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# loading csv\n",
    "csv_path = 'data/tiktok_dataset.csv'\n",
    "tiktok_data = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating db in data along with connection\n",
    "db_file_path = os.path.join(folder_path, \"tiktok.db\")\n",
    "conn = sqlite3.connect(db_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7d679570cd50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor = conn.cursor()\n",
    "# Create tables\n",
    "\n",
    "# 1. Videos table\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS Videos (\n",
    "    video_id INTEGER PRIMARY KEY,\n",
    "    video_duration_sec INTEGER,\n",
    "    claim_status TEXT,\n",
    "    verified_status TEXT,\n",
    "    video_transcription_text TEXT\n",
    ")\n",
    "''')\n",
    "\n",
    "# 2. Authors table\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS Authors (\n",
    "    author_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    author_ban_status TEXT\n",
    ")\n",
    "''')\n",
    "\n",
    "# 3. VideoMetrics table\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS VideoMetrics (\n",
    "    metric_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    video_id INTEGER,\n",
    "    video_view_count REAL,\n",
    "    video_like_count REAL,\n",
    "    video_share_count REAL,\n",
    "    video_download_count REAL,\n",
    "    video_comment_count REAL,\n",
    "    FOREIGN KEY (video_id) REFERENCES Videos(video_id)\n",
    ")\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Insert data into these tables\n",
    "\n",
    "# Track unique authors and their ban status\n",
    "authors = {}\n",
    "\n",
    "for _, row in tiktok_data.iterrows():\n",
    "    # Insert into Videos table\n",
    "    cursor.execute('''\n",
    "        INSERT OR IGNORE INTO Videos (video_id, video_duration_sec, claim_status, verified_status, video_transcription_text)\n",
    "        VALUES (?, ?, ?, ?, ?)\n",
    "    ''', (row['video_id'], row['video_duration_sec'], row['claim_status'], row['verified_status'], row['video_transcription_text']))\n",
    "\n",
    "    # Insert into Authors table if unique\n",
    "    author_ban_status = row['author_ban_status']\n",
    "    if author_ban_status not in authors:\n",
    "        cursor.execute('''\n",
    "            INSERT INTO Authors (author_ban_status)\n",
    "            VALUES (?)\n",
    "        ''', (author_ban_status,))\n",
    "        authors[author_ban_status] = cursor.lastrowid  # Store the author_id for reference\n",
    "    \n",
    "    # Insert into VideoMetrics table\n",
    "    cursor.execute('''\n",
    "        INSERT INTO VideoMetrics (video_id, video_view_count, video_like_count, video_share_count, video_download_count, video_comment_count)\n",
    "        VALUES (?, ?, ?, ?, ?, ?)\n",
    "    ''', (row['video_id'], row['video_view_count'], row['video_like_count'], row['video_share_count'], row['video_download_count'], row['video_comment_count']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Commit changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7017666017, 59, 'claim', 343296.0, 19425.0), (4014381136, 32, 'claim', 140877.0, 77355.0), (9859838091, 31, 'claim', 902185.0, 97690.0), (1866847991, 25, 'claim', 437506.0, 239954.0), (7105231098, 19, 'claim', 56167.0, 34987.0)]\n"
     ]
    }
   ],
   "source": [
    "# connecting and testing a query\n",
    "conn = sqlite3.connect(db_file_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "query = '''\n",
    "SELECT v.video_id, v.video_duration_sec, v.claim_status, m.video_view_count, m.video_like_count\n",
    "FROM Videos v\n",
    "JOIN VideoMetrics m ON v.video_id = m.video_id\n",
    "LIMIT 5\n",
    "'''\n",
    "result = cursor.execute(query).fetchall()\n",
    "print(result)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Api Calls to Youtube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a fucntion to make api calls to youtube to get metrics of youtube videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from googleapiclient.discovery import build\n",
    "import json\n",
    "\n",
    "# Get the YouTube API key from the environment\n",
    "YOUTUBE_API_KEY = os.getenv(\"YOUTUBE_API_KEY\")\n",
    "\n",
    "# Initialize the YouTube API client\n",
    "youtube = build(\"youtube\", \"v3\", developerKey=YOUTUBE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_video_ids(query, max_results=50):\n",
    "    # Retrieve video IDs based on the search query\n",
    "    request = youtube.search().list(\n",
    "        part=\"id\",\n",
    "        q=query,\n",
    "        type=\"video\",\n",
    "        maxResults=max_results\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    # Extract video IDs from the response\n",
    "    video_ids = [item[\"id\"][\"videoId\"] for item in response.get(\"items\", [])]\n",
    "    return video_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_video_metrics(video_ids):\n",
    "    # Retrieve video details including metrics\n",
    "    request = youtube.videos().list(\n",
    "        part=\"snippet,contentDetails,statistics\",\n",
    "        id=\",\".join(video_ids)\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    # Collect relevant metrics in a structured format\n",
    "    video_data = []\n",
    "    for item in response.get(\"items\", []):\n",
    "        video_info = {\n",
    "            \"video_id\": item[\"id\"],\n",
    "            \"title\": item[\"snippet\"][\"title\"],\n",
    "            \"channel_title\": item[\"snippet\"][\"channelTitle\"],\n",
    "            \"published_at\": item[\"snippet\"][\"publishedAt\"],\n",
    "            \"view_count\": int(item[\"statistics\"].get(\"viewCount\", 0)),\n",
    "            \"like_count\": int(item[\"statistics\"].get(\"likeCount\", 0)),\n",
    "            \"comment_count\": int(item[\"statistics\"].get(\"commentCount\", 0)),\n",
    "            \"duration\": item[\"contentDetails\"][\"duration\"]\n",
    "        }\n",
    "        video_data.append(video_info)\n",
    "\n",
    "    return video_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fetch video IDs based on search query\n",
    "video_ids = get_video_ids(query=\"Harris\", max_results=50)\n",
    "\n",
    "# Split video IDs into batches of 50 to stay within API limits\n",
    "batch_size = 50\n",
    "all_video_data = []\n",
    "for i in range(0, len(video_ids), batch_size):\n",
    "    batch_ids = video_ids[i:i + batch_size]\n",
    "    all_video_data.extend(get_video_metrics(batch_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>published_at</th>\n",
       "      <th>view_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Xe7TuOlyUIM</td>\n",
       "      <td>Kamala supporters told to leave Harris HQ</td>\n",
       "      <td>Sky News Australia</td>\n",
       "      <td>2024-11-06T06:00:14Z</td>\n",
       "      <td>237002</td>\n",
       "      <td>3980</td>\n",
       "      <td>3062</td>\n",
       "      <td>PT1M21S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0QLZB6djGAA</td>\n",
       "      <td>LIVE election results, analysis</td>\n",
       "      <td>ABC 7 Chicago</td>\n",
       "      <td>2024-11-06T11:20:05Z</td>\n",
       "      <td>2244135</td>\n",
       "      <td>7182</td>\n",
       "      <td>267</td>\n",
       "      <td>PT9H49M30S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zZVO0mQFg9s</td>\n",
       "      <td>Kamala Harris won't speak at watch party</td>\n",
       "      <td>CNBC Television</td>\n",
       "      <td>2024-11-06T06:08:22Z</td>\n",
       "      <td>112507</td>\n",
       "      <td>940</td>\n",
       "      <td>3013</td>\n",
       "      <td>PT2M15S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uJE07Lpoom8</td>\n",
       "      <td>Trump supporters celebrate as Harris backs out...</td>\n",
       "      <td>news.com.au</td>\n",
       "      <td>2024-11-06T06:43:19Z</td>\n",
       "      <td>316297</td>\n",
       "      <td>7229</td>\n",
       "      <td>4156</td>\n",
       "      <td>PT50S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FMPSk8Fvt04</td>\n",
       "      <td>Deafening silence at Democrat HQ as Kamala Har...</td>\n",
       "      <td>Sky News Australia</td>\n",
       "      <td>2024-11-06T06:10:01Z</td>\n",
       "      <td>379885</td>\n",
       "      <td>9243</td>\n",
       "      <td>5741</td>\n",
       "      <td>PT6M5S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                              title  \\\n",
       "0  Xe7TuOlyUIM          Kamala supporters told to leave Harris HQ   \n",
       "1  0QLZB6djGAA                    LIVE election results, analysis   \n",
       "2  zZVO0mQFg9s           Kamala Harris won't speak at watch party   \n",
       "3  uJE07Lpoom8  Trump supporters celebrate as Harris backs out...   \n",
       "4  FMPSk8Fvt04  Deafening silence at Democrat HQ as Kamala Har...   \n",
       "\n",
       "        channel_title          published_at  view_count  like_count  \\\n",
       "0  Sky News Australia  2024-11-06T06:00:14Z      237002        3980   \n",
       "1       ABC 7 Chicago  2024-11-06T11:20:05Z     2244135        7182   \n",
       "2     CNBC Television  2024-11-06T06:08:22Z      112507         940   \n",
       "3         news.com.au  2024-11-06T06:43:19Z      316297        7229   \n",
       "4  Sky News Australia  2024-11-06T06:10:01Z      379885        9243   \n",
       "\n",
       "   comment_count    duration  \n",
       "0           3062     PT1M21S  \n",
       "1            267  PT9H49M30S  \n",
       "2           3013     PT2M15S  \n",
       "3           4156       PT50S  \n",
       "4           5741      PT6M5S  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Convert to a DataFrame for easy analysis\n",
    "df_videos = pd.DataFrame(all_video_data)\n",
    "df_videos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mongoDB_practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
